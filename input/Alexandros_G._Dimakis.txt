Professor: Alexandros G. Dimakis
University: University of Texas at Austin
URL: http://users.ece.utexas.edu/~dimakis
Description: Home
Main
Bio and CV
Research
Projects
Group
Papers
By Type
Scholar Profile
Courses
Teaching
Activities
Service and TPCs
Fun
Artistic Attempts
	
Alexandros G. Dimakis (Alex Dimakis)
 	

Professor, Chandra Department of Electrical and Computer Engineering

Professor, Department of Computer Science

Director, Center for Generative AI

Co-Director of the National AI Institute for Foundations of Machine Learning

Stanly P. Finch Centennial Professorship in Engineering

Member of the Wireless Networking and Communications Group

Twitter
Office: 2501 Speedway, EER Building Room 6.816 Austin, Texas 78701


dimakis at austin.utexas.edu




I am interested in information theory, coding theory and machine learning. Resume.

Google Scholar Profile.

News

We are hiring postdocs at the new NSF Institute for Foundations of Machine Learning
(News release)

Four papers accepted to NeurIPS 2023


S. Gadre, G. Ilharco, A. Fang, J. Hayase, G. Smyrnis, T. Nguyen, R. Marten, M. Wortsman, D. Ghosh, J. Zhang, E. Orgad,
R. Entezari, G. Daras, S. M. Pratt, V. Ramanujan, Y. Bitton, K. Marathe, S. Mussmann, R. Vencu, M. Cherti, R. Krishna,
P. W. Koh, O. Saukh, A. Ratner, S. Song, H. Hajishirzi, A. Farhadi, R. Beaumont, S. Oh, A.G. Dimakis,
J. Jitsev, Y. Carmon, V. Shankar, L. Schmidt,
“DataComp: In search of the next generation of multimodal datasets”
Proc. of Neural Information Processing Systems (NeurIPS), Dec. 2023. Datasets and Benchmarks Track,
Selected for Oral presentation.
https://www.datacomp.ai/ (Project Page)

G. Daras, K. Shah, Y. Dagan, A. Gollakota, A. G. Dimakis, A. R. Klivans,
“Ambient Diffusion: Learning Clean Distributions from Corrupted Data,”
Proc. of Neural Information Processing Systems (NeurIPS), Dec. 2023.
(Project Page) (Arxiv), (Code).


L. Rout, N. Raoof, G. Daras, C. Caramanis, A. G. Dimakis, S. Shakkottai,
“Solving Inverse Problems Provably via Posterior Sampling with Latent Diffusion Models,”
Proc. of Neural Information Processing Systems (NeurIPS), Dec. 2023. (Project Page), (Arxiv),(Code)

G. Daras, Y. Dagan, A.G. Dimakis, C. Daskalakis,
“Martingale Diffusion Models: Mitigating Sampling Drift by Learning to be Consistent,
” Proc. of Neural Information Processing Systems (NeurIPS), Dec. 2023. (Project Page)

Our paper on deep learning for time-series modeling used for electronic system design and electromagnetic (EM) interconnect analysis for signal integrity, accepted to ICCAD:

S. Ravula, V. Gorti, B. Deng, S. Chakraborty, J. Pingenot, B. Mutnury, D. Wallace, D. Winterberg, A. R. Klivans, A. G. Dimakis,
“One-Dimensional Deep Image Prior for Curve Fitting of S-Parameters from Electromagnetic Solvers,”
2023 International Conference on Computer-Aided Design (ICCAD 2023) (Project Page)

T. Chen, C. Gong, D. J. Diaz, X. Chen, J. T. Wells, Q. Liu, Z. Wang, A. D. Ellington, A.G. Dimakis, A. R. Klivans,
“HotProtein: A Novel Framework for Protein Thermostability Prediction and Editing,”
Proceedings on the International Conference on Representation Learning (ICLR 2023).

Elected IEEE Fellow for contributions to distributed coding and learning, 2022.

Selected as Commissioner. Artificial Intelligence Commission on Competition, Inclusion, and Innovation
by the US Chamber of Commerce to provide a roadmap for tech leadership to US policy makers.

Faculty of the year award (for 2022). MS Program in Information Technology Management, (Voted by students).

Keynote speaker, 14th IEEE Image and Multidimensional Signal Processing Workshop (IVMSP) 2022.

Plenary speaker, 13th International Conference on the Image, 2022.

Best Paper Award at UAI 2021 Workshop on Tractable Probabilistic Modeling.

Recent talk: Generative models are the new sparsity
Recent Berkeley Simons talk on deep generative models and how they can be used to solve inverse problems including Denoising, Missing data, Compressed Sensing and MRI.

G. Daras, N. Raoof, Z. Gkalitsiou and A.G. Dimakis
‘‘Multitasking Models are Robust to Structural Failure: A Neural Model for Bilingual Cognitive Reserve,’’
Proc. of Neural Information Processing Systems (NeurIPS), Dec. 2022.
(Project Page) arxiv

M. Jordan, J. Hayase, A. G. Dimakis, S. Oh
‘‘Zonotope Domains for Lagrangian Neural Network Verification,’’
Proc. of Neural Information Processing Systems (NeurIPS), Dec. 2022.
(Arxiv)

G. Daras, Y. Dagan, A. G. Dimakis, C. Daskalakis
‘‘Score-Guided Intermediate Level Optimization: Fast Langevin Mixing for Inverse Problems.’’
International Conference on Machine Learning (ICML), 2022.
(Project Page)

J. Whang, M. Delbracio, H. Talebi, C. Saharia, A. G. Dimakis, P. Milanfar,
‘‘Deblurring via Stochastic Refinement.’’
Computer Vision and Pattern Recognition (CVPR) June 2022. (Oral Presentation) (Arxiv)

Two papers accepted to NeurIPS 2021


Ajil Jalal, Marius Arvinte, Giannis Daras, Eric Price, Alexandros G. Dimakis and Jonathan I. Tamir,
Robust Compressed Sensing MRI with Deep Generative Priors,
(Project Page), (Arxiv)

Sriram Ravula, Georgios Smyrnis ,Matt Jordan, Alexandros G. Dimakis
Inverse Problems Leveraging Pre-trained Contrastive Representations
(Project Page) (Arxiv)


Six papers accepted to ICML 2021


Ajil Jalal, Sushrut Karmalkar, A.G. Dimakis and E. Price,
Instance-Optimal Compressed Sensing via Posterior Sampling,
(Project Page)

Ajil Jalal, Jessica Hoffmann, Sushrut Karmalkar, A.G. Dimakis and E. Price,
Fairness for Image Generation with Uncertain Sensitive Attributes
(Project page)

Giannis Daras, Joseph Dean, Ajil Jalal, and A.G. Dimakis,
Intermediate Layer Optimization for Inverse Problems using Deep Generative Models
(Project Page)

Matt Jordan, A.G. Dimakis,
Provable Lipschitz Certification for Generative Models
(Arxiv), (Code)

Jay Whang, Qi Lei, A.G. Dimakis
Solving Inverse Problems with a Flow-based Noise Model
(Arxiv)

Jay Whang, Erik Lindgren, A.G. Dimakis,
Composing Normalizing Flows for Inverse Problems
(Arxiv)
Best Paper Award at UAI 2021 Workshop on Tractable Probabilistic Modeling

Congratulations to Qi Lei for winning the Oden Institute Outstanding Dissertation Award for her awesome Phd dissertation

Recent service:

TPC chair for MLSys 2021

AAAI 2021 Area chair, NeurIPS 2020 Area chair

New paper: Intermediate Layer Optimization for Inverse Problems using Deep Generative Models
by G. Daras, J. Dean, A. Jalal and A.G. Dimakis. (Code) (Paper)

Four papers accepted to NeurIPS 2020


A. Jalal, L. Liu, A.G. Dimakis and C. Caramanis,
Robust compressed sensing of generative models, (arxiv)

M. Jordan and A.G. Dimakis,
Exactly Computing the Local Lipschitz Constant of ReLU Networks, (arxiv)

I. Daras, N. Kitaev, A. Odena and A.G. Dimakis
SMYRF - Efficient attention using asymmetric clustering (arxiv)

M. Kocaoglu, S. Shakkottai, A.G. Dimakis, C. Caramanis and S. Vishwanath
Applications of Common Entropy in Causal Inference (pdf)

New Survey: Deep Learning Techniques for Inverse Problems in Imaging
G. Ongie, A. Jalal, C. A. Metzler, R. G. Baraniuk, A. G. Dimakis and R. Willett
Journal on Selected Areas in Information Theory, May 2020. (arxiv), ieeeXplore

Your Local GAN: Designing Two Dimensional Local Attention Mechanisms for Generative Models
Giannis Daras, Augustus Odena, Han Zhang, Alexandros G. Dimakis, CVPR 2020.
(arxiv) | Code | Colab Notebook | Twitter Thread

Deep Generative models and Inverse Problems, talk at 2019 Texas AI summit
(Slides.pdf) (Slides.pptx)
Related Video: GANs and Compressed Sensing talk

Gradient Coding from Cyclic MDS Codes and Expander Graphs
N. Raviv, I. Tamo, R. Tandon and A. G. Dimakis, IEEE Transactions on Information Theory
(arxiv)

Five papers accepted to NeurIPS 2019


Matt Jordan , Justin Lewis, Alexandros G. Dimakis
Provable Certificates for Adversarial Examples: Fitting a Ball in the Union of Polytopes
(pdf)

Qi Lei, Ajil Jalal, Inderjit S. Dhillon, and Alexandros G. Dimakis
Inverting Deep Generative models, One layer at a time.
(pdf)

Qi Lei, Jiacheng Zhuo, Constantine Caramanis, Inderjit S Dhillon, Alexandros G Dimakis
Primal-Dual Block Frank-Wolfe
(pdf)

Shanshan Wu, Sujay Sanghavi, Alexandros G. Dimakis
Sparse Logistic Regression Learns All Discrete Pairwise Graphical Models (Spotlight)
(pdf)

Shanshan Wu, Alexandros G. Dimakis, Sujay Sanghavi
Learning Distributions Generated by One-Layer ReLU Networks
(pdf)

SysML 2019 paper on adversarial attacks on text classifiers


Q. Lei, L. Wu, P. Chen, A.G. Dimakis, I.S. Dhillon and M. Witbrock,
Discrete Adversarial Attacks and Submodular Optimization with Applications to Text Classification
Systems and Machine Learning (SysML), April 2019. (pdf) slides code

Press coverage: Nature News, VentureBeat, TechTalks

ICML 2019 paper on learned compressed sensing matrices


S. Wu, A.G. Dimakis, S. Sanghavi, F.X. Yu, D. Holtmann-Rice, D. Storcheus, A. Rostamizadeh, S. Kumar,
Learning a Compressed Sensing Measurement Matrix via Gradient Unrolling
International Conference on Machine Learning (ICML), 2019. (slides) (pdf) (Tensorflow Code)

New Paper accepted to NeurIPS 2018


Erik Lindgren, Murat Kocaoglu, A.G. Dimakis and Sriram Vishwanath
Experimental Design for Cost-Aware Learning of Causal Graphs
Neural Information Processing Systems, 2019. (pdf) (Short video ft. Erik's radio voice)

Preprint

D. Van Veen, A. Jalal, E. Price, S. Vishwanath, and A.G. Dimakis
Compressed Sensing with Deep Image Prior and Learned Regularization
https:arxiv.orgabs1806.06438 (arxiv) (Code)

Preprint

The Robust Manifold Defense: Adversarial Training using Generative Models
A. Ilyas, A. Jalal, E. Asteri, C. Daskalakis, A. G. Dimakis
(arxiv)


Paper accepted to Annals of Statistics

E. R. Elenberg, R. Khanna, A.G. Dimakis, and S. Negahban
‘‘Restricted Strong Convexity Implies Weak Submodularity’’,
to appear in Annals of Statistics, 2018.
(preprint)

Teaching resources for Data Science and Machine learning

Honored to receive the James Massey award

NeurIPS, ICML, AISTATS Area chair

Compressed Sensing using Generative models Pre-trained models see also GitHub CSGM

ICLR 2018

A. Bora, E. Price, A.G. Dimakis
AmbientGAN: Generative models from lossy measurements
(Oral Presentation) (openreview), (code)


M. Kocaoglu, C. Snyder, A.G. Dimakis and S. Vishwanath
CausalGAN: Learning Causal Implicit Generative Models with Adversarial Training
(arxiv) (code)

NIPS 2017:

E.R. Elenberg, A.G. Dimakis, M. Feldman, and A. Karbasi
‘‘Streaming Weak Submodularity: Interpreting Neural Networks on the Fly’’,
(NIPS), 2017. (Oral presentation) (arxiv) code


Model-Powered Conditional Independence Test R. Sen, A.T. Suresh, K. Shanmugam, A.G. Dimakis and S. Shakkottai (NIPS), 2017.

Preprint

Gradient Coding from Cyclic MDS Codes and Expander Graphs
N Raviv, I Tamo, R Tandon, AG Dimakis (arxiv)

Six papers accepted to ICML 2017:

Compressed Sensing using Generative Models (arxiv) Code and Demo
A. Bora, A. Jalal, E. Price, A. G. Dimakis

Gradient Coding (pdf)
R. Tandon, Q. Lei, A. G. Dimakis, N. Karampatziakis. (Slides from ITA)

On Approximation Guarantees for Greedy Low Rank Optimization (arxiv)
R. Khanna, E. Elenberg, A. G. Dimakis, S. Negahban.

Exact MAP Inference by Avoiding Fractional Vertices (arxiv)
E. M. Lindgren, A. G. Dimakis, A. Klivans.

Cost-Optimal Learning of Causal Graphs (arxiv)
M. Kocaoglu, A. G. Dimakis, S. Vishwanath.

Identifying Best Interventions through Online Importance Sampling (arxiv)
R. Sen, K. Shanmugam, A. G. Dimakis and S. Shakkottai.

Two papers accepted to ISIT 2017:

Entropic Causality and Greedy Minimum Entropy Coupling (arxiv)
M. Kocaoglu, A. G. Dimakis, S. Vishwanath and B. Hassibi.

Coded Caching with Linear Subpacketization is Possible using Ruzsa-Szeméredi Graphs. (arxiv)
K. Shanmugam, A. M. Tulino and A. G. Dimakis.


Recent work on decoding brain signals using interpretable features:

H. Yi, Z. Xie, R. Reetzke, A.G. Dimakis and B. Chandrasekaran.
Vowel decoding from single-trial speech-evoked electrophysiological responses: A feature-based machine learning approach.
Brain and Behavior. April 2017; (Open Access)


Check the cool projects from our undergraduate Data Science Lab course

Entropic Causality paper to appear in AAAI 2017. (Arxiv)
More information

Two papers accepted to AISTATS 2017:

Contextual Bandits with Latent Confounders: An NMF Approach (pdf)
R. Sen, K. Shanmugam, M. Kocaoglu, A. G. Dimakis and S. Shakkottai.

Scalable Greedy Feature Selection via Weak Submodularity. (pdf)
R. Khanna, E. Elenberg, A. G. Dimakis, S. Neghaban and J. Ghosh

Slides and notes from GraphDay overview talk on graph analytics and machine learning (pdf)

Upcoming talk at Canadian Workshop on Information Theory (CWIT) (CWIT link)

Two papers accepted to NIPS 2016:

Leveraging Sparsity for Efficient Submodular Data Summarization
E. Lindgren, S. Wu, A. G. Dimakis (pdf)

Single Pass PCA of Matrix Products S. Wu, S. Bhojanapalli, S. Sanghavi, A. G. Dimakis (pdf)

Preprint: Restricted Strong Convexity Implies Weak Submodularity
E. Elenberg, R. Khanna, A. G. Dimakis, S. Negahban (pdf)

Distributed Estimation of Graph 4-profiles
E. R. Elenberg, K. Shanmugam, M. Borokhovich, A. G. Dimakis.
in Proc. International World Wide Web Conference (WWW), 2016 (Arxiv)

Bipartite Correlation Clustering: Maximizing Agreements
M. Asteris, A. Kyrillidis, D. Papailiopoulos, A. G. Dimakis, AISTATS 2016 (pdf)

Three papers accepted to NIPS 2015

Orthogonal NMF through Subspace Exploration
M. Asteris D. Papailiopoulos A. G. Dimakis (pdf)

Sparse PCA via Bipartite Matchings
M. Asteris D. Papailiopoulos A. Kyrillidis A. G. Dimakis (pdf)

Learning Causal Graphs with Small Interventions
K. Shanmugam, M. Kocaoglu, A.G. Dimakis, S. Vishwanath (arxiv)

Stay on path: PCA along graph paths M. Asteris A. Kyrillidis A. G. Dimakis H. Yi B. Chandrasekaran International Conference on Machine Learning (ICML), Lille, France, 2015, (pdf) (slides)

E.R. Elenberg, K. Shanmugam, M. Borokhovich and A.G. Dimakis,
Beyond Triangles: A Distributed Framework for Estimating 3-profiles of Large Graphs (KDD 2015, to appear)

I. Mitliagkas, M. Borokhovich, A.G. Dimakis and C. Caramanis, FrogWild!-Fast PageRank Approximations on Graph Engines (to appear in VLDB 2015).

Two papers accepted to ISIT 2015

On approximating the sum-rate for multiple unicasts K. Shanmugam, M. Asteris and A.G. Dimakis

Batch Codes through Dense Graphs with High Girth A.S. Rawat, Z. Song, A.G. Dimakis and A. Gal

Two papers accepted in NIPS 2014.

Sparse Polynomial Learning and Graph Sketching (Oral)
M. Kocaoglu, K. Shanmugam, A.G. Dimakis, A. Klivans

On the Information Theoretic Limits of Learning Ising Models
R. Tandon, K. Shanmugam, P. Ravikumar, A.G. Dimakis

Batch Codes through Dense Graphs without Short Cycles A.G. Dimakis, A. Gal, A.S. Rawat, Z. Song

Invited talk on coding theory for distributed storage at Algebra Codes and Networks at Bordaux. Talk Slides.

Two papers accepted in ICML 2014.

Nonnegative Sparse PCA with Provable Guarantees
M. Asteris, D. Papailiopoulos, A.G. Dimakis
ICML video

Finding Dense Subgraphs via Low-Rank Bilinear Optimization
D. Papailiopoulos, I. Mitliagkas, A.G. Dimakis, C. Carmanis
ICML video

Three papers accepted in ISIT 2014.

Bounding Multiple Unicasts through Index Coding and Locally Repairable Codes

Graph Theory versus Minimum Rank for Index Coding

Locality and Availability in Distributed Storage

Our Locally Repairable Storage codes featured on High Scalability, StorageMojo and TechCrunch.

Online Milibo tutorial Erasure codes over Hadoop

New paper: Sparse PCA through Low-rank Approximations (to appear in ICML 2013). video of Sparse PCA talk

Our Xorbas Hadoop locally repairable codes paper will appear in VLDB 2013. Visit the Xorbas HDFS project homepage.

I have moved to UT Austin. My USC homepage will no longer be updated.

Received a Google Faculty Research Award. Support gratefully acknowledged.

Our paper received the Communications Society & Information Theory Society Joint Paper Award.

I maintain the Distributed Storage Wiki, an online bibliography about theoretical problems in large-scale distributed storage systems. (Temprary offline, will need new host for this)

Page generated 2023-10-05 13:49:15 CDT, by jemdoc.

