Professor: Heng Fan 0001
University: University of North Texas
URL: https://hengfan2010.github.io/
Description: Home Selected Publications Group Teaching Professional Activities
        Heng Fan
       Assistant Professor
       Department of Computer Science and Engineering, University of North Texas
       Office: Room F284, UNT Discovery Park, 3940 N Elm St, Denton, TX 76207
       Email: heng.fan@unt.edu
       [Curriculum Vitae] [Google Scholar] [LinkedIn] [DBLP] [AI Seminar]
Short Bio

Heng Fan is currently an Assistant Professor in the Department of Computer Science and Engineering at the University of North Texas. He received his B.S. from Huazhong Agricultural University in 2013 and Ph.D. (advised by Professor Haibin Ling) from Stony Brook University in 2021, respectively. His research interests include computer vision with a particular interest in various video analysis tasks using vision and language, robotics with a focus on robot vision perception, and medical image analysis. He has served as a guest editor for ACM Journal on Autonomous Transportation Systems (ACM JATS) and as Area Chairs for WACV 2022-2025.

To prospective students: I am looking for self-motivated PhD/master/undergraduate/TAMS students to work on interesting problems in computer and robotic vision. If you are interested, please read HERE.
News 
2024-07: A paper on multi-view 3D object detection and tracking (pdf) is accepted to IJCV.
2024-07: Two papers on object tracking (pdf/code, pdf/code) are accepted to ECCV 2024.
2024-07: Two oral papers on efficient segmentation (pdf/code) and 3D detection (pdf/code) are accepted to IROS 2024.
2024-06: A paper on domain adaptive object detection (pdf/code) is accepted to PAMI.
2024-06: I will serve as an Area Chair for WACV 2025.
2024-05: A paper on vision-language tracking (pdf/code) is accepted to PAMI.
2024-03: Our AttMOT (pdf/code) is accepted to IEEE Transactions on Neural Networks and Learning Systems.
2024-03: Present VastTrack (pdf/code-data), containing over 2.1K classes/50K videos for vast category visual tracking.
2024-02: Three papers (pdf/code, pdf, pdf) are accepted to CVPR 2024.
2024-01: Welcome PhD student Bing Fan to join our team.
2024-01: Our MaGIC for multimodal guided image completion (pdf/project/code) is accepted to ICLR 2024.
Quick Links
      myUNT   EagleConnect   UNT CSE   UNT Directory   UNT Map   Google   gScholar   gMap   CVF   IEEE   CSRankings

