Professor: Hongchang Gao
University: Temple University
URL: https://www.cst.temple.edu/~tuo14379
Description: Menu
Home
Research
Publications
Teaching
Students
Services
	
Hongchang Gao
 	

Assistant Professor
Department of Computer and Information Sciences
College of Science and Technology
Temple University

Email: hongchang.gao AT temple DOT edu
Office: Room 318, Science Education and Research Center (SERC)
Address: 1925 N. 12th Street, Philadelphia, PA 19122-1801
[Google Scholar] [Github]

Brief biography

Hongchang Gao joined the CIS department of Temple University as a tenure-track Assistant Professor in 2020. Prior to this, he received his Ph.D. degree in Electrical and Computer Engineering from University of Pittsburgh in 2020 under the supervision of Dr. Heng Huang, M.S. degree in Computer Science from Beihang University in 2014, and B.S. degree in Mathematics and Applied Mathematics from Ocean University of China in 2011.


Research interests

Machine/Deep Learning, Optimization

Data Mining, Biomedical Data Science

Recent news

05/2024: Thrilled to receive NSF CAREER Award. Thanks NSF!

05/2024: I will serve as an Area Chair for NeurIPS 2024.

05/2024: Two papers on Federated Learning were accepted to ICML 2024 (acceptance rate: 27.5%).

04/2024: Gave an invited talk about Decentralized Stochastic Bilevel Optimization at Applied Mathematics and Scientific Computing Seminar at Temple University.

01/2024: I will serve as an Area Chair for ICML 2024.

01/2024: Two papers on Large-scale Optimization and Fairness Learning were accepted to AISTATS 2024 (acceptance rate: 27%).

12/2023: One paper on Federated Learning was accepted to SDM 2024 (acceptance rate: 29.2%).

12/2023: One paper on Generative Model was accepted to AAAI 2024 (acceptance rate: 23.75%).

10/2023: One tutorial on Distributed Nested Optimization was accepted to AAAI 2024.

09/2023: One paper on Federated Learning was accepted to NeurIPS 2023.

07/2023: Invited to serve as an SPC member of AAAI 2024.

07/2023: Thrilled to receive Cisco Faculty Research Award.

07/2023: One paper on Vision-Language Pre-training Models was accepted to ICCV 2023.

06/2023: One paper on Federated Learning was accepted to ICPP 2023.

05/2023: One tutorial ‘‘Distributed Optimization for Big Data Analytics: Beyond Minimization’’ was accepted to KDD 2023.

04/2023: One paper on Large-scale Optimization was accepted to IJCAI 2023 (acceptance rate: 15%).

01/2023: One paper on Large-scale Optimization was accepted to AISTATS 2023 (acceptance rate: 29%).

01/2023: One paper on Federated Learning was accepted to IEEE Network.

12/2022: Invited to serve as Tutorial Chair of ICDM 2023.

11/2022: Selected for AAAI 2023 New Faculty Highlights program.

07/2022: Invited to serve as an SPC member of AAAI 2023.

05/2022: Two papers on Federated Learning and Large-scale Optimization were accepted to ICML 2022 (acceptance rate: 21.9%).

03/2022: Invited to serve as an Associate Editor of Journal of Combinatorial Optimization.

03/2022: Invited to serve as Student Volunteer Chair of ICDM 2022.

01/2022: One paper on Self-supervised Learning was accepted to WWW 2022 (acceptance rate: 17%).

12/2021: One paper on Large-scale Optimization was accepted to AAAI 2022 (acceptance rate: 15%).

09/2021: One paper on Large-scale Optimization was accepted to NeurIPS 2021 (acceptance rate: 26%).

08/2021: Invited to serve as an SPC member of AAAI 2022.

05/2021: One paper on Data Privacy Protection was accepted to KDD 2021 (acceptance rate: 15.4%).

04/2021: Two papers on Large-scale Optimization were accepted to IJCAI 2021 (acceptance rate: 13.9%).

12/2020: Two papers on Large-scale Optimization were accepted to SDM 2021 (acceptance rate: 21.25%).

12/2020: One paper on Federated Learning was accepted to AAAI 2021 (acceptance rate: 21%).

11/2020: Invited to serve as an SPC member of IJCAI 2021.

08/2020: Invited to serve as Session Chair of KDD 2020.

05/2020: One paper on Large-scale Optimization was accepted to ICML 2020 (acceptance rate: 21.8%).

Page generated 2024-05-29 00:28:29 EDT, by jemdoc.

