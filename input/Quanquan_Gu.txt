Professor: Quanquan Gu
University: Univ. of California - Los Angeles
URL: http://web.cs.ucla.edu/~qgu
Description: Home
Research
Publications
Teaching
Talks
Service
Group
	
Quanquan Gu

pronunciation

Associate Professor
Department of Computer Science
University of California, Los Angeles

I am an Associate Professor of Computer Science at UCLA. I am leading the UCLA Artificial General Intelligence Lab. I received my Ph.D. degree in Computer Science from the University of Illinois at Urbana-Champaign in 2014. My research is in artificial intelligence and machine learning, with a focus on nonconvex optimization, deep learning, reinforcement learning, Large Language Models (LLMs), and deep generative models (e.g., diffusion models). Recently, I have been utilizing AI to enhance scientific discovery in domains such as biology, medicine, chemistry, and public health.

Here is my latest CV.

News and Annoucement

[Nov 28, 2023] We are oragnizing the New Frontiers of AI for Drug Discovery and Development at NeurIPS 2023.

Recent Research Highlight

Self-Play Preference Optimization for Language Model Alignment
Yue Wu*, Zhiqing Sun*, Huizhuo Yuan*, Kaixuan Ji, Yiming Yang and Quanquan Gu, arXiv:2405.00675, 2024.

Self-Play Fine-Tuning of Diffusion Models for Text-to-Image Generation
Huizhuo Yuan*, Zixiang Chen*, Kaixuan Ji* and Quanquan Gu, arXiv:2402.10210, 2024.

Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models
Zixiang Chen*, Yihe Deng*, Huizhuo Yuan*, Kaixuan Ji and Quanquan Gu, in Proc. of the 41th International Conference on Machine Learning (ICML), Vienna, Austria, 2024. [arXiv]

Implicit Bias of Gradient Descent for Two-layer ReLU and Leaky ReLU Networks on Nearly-orthogonal Data
Yiwen Kou*, Zixiang Chen* and Quanquan Gu, in Proc. of Advances in Neural Information Processing Systems (NeurIPS) 36, New Orleans, LA, USA, 2023. [arXiv]

Why Does Sharpness-Aware Minimization Generalize Better Than SGD?
Zixiang Chen*, Junkai Zhang*, Yiwen Kou, Xiangning Chen, Cho-Jui Hsieh and Quanquan Gu, in Proc. of Advances in Neural Information Processing Systems (NeurIPS) 36, New Orleans, LA, USA, 2023. [arXiv]

Nearly Minimax Optimal Reinforcement Learning for Linear Markov Decision Processes
Jiafan He, Heyang Zhao, Dongruo Zhou and Quanquan Gu, in Proc. of the 40th International Conference on Machine Learning (ICML), Hawaii, USA, 2023. [arXiv]

Benign Overfitting for Two-layer ReLU Convolutional Neural Networks
Yiwen Kou*, Zixiang Chen*, Yuanzhou Chen and Quanquan Gu, in Proc. of the 40 th International Conference on Machine Learning (ICML), Hawaii, USA, 2023. [arXiv]

Variance-Dependent Regret Bounds for Linear Bandits and Reinforcement Learning: Adaptivity and Computational Efficiency
Heyang Zhao, Jiafan He, Dongruo Zhou, Tong Zhang and Quanquan Gu, in Proc. of the 36th Annual Conference on Learning Theory (COLT), Bangalore, India, 2023. [arXiv]

Computationally Efficient Horizon-Free Reinforcement Learning for Linear Mixture MDPs
Dongruo Zhou and Quanquan Gu, in Proc. of Advances in Neural Information Processing Systems (NeurIPS) 35, New Orleans, LA, USA, 2022. Oral Presentation [arXiv]

Nearly Optimal Algorithms for Linear Contextual Bandits with Adversarial Corruptions
Jiafan He, Dongruo Zhou, Tong Zhang and Quanquan Gu, in Proc. of Advances in Neural Information Processing Systems (NeurIPS) 35, New Orleans, LA, USA, 2022. [arXiv]

Risk Bounds of Multi-Pass SGD for Least Squares in the Interpolation Regime
Difan Zou*, Jingfeng Wu*, Vladimir Braverman, Quanquan Gu and Sham M. Kakade, in Proc. of Advances in Neural Information Processing Systems (NeurIPS) 35, New Orleans, LA, USA, 2022. [arXiv]

Benign Overfitting in Two-layer Convolutional Neural Networks
Yuan Cao*, Zixiang Chen*, Mikhail Belkin and Quanquan Gu, in Proc. of Advances in Neural Information Processing Systems (NeurIPS) 35, New Orleans, LA, USA, 2022. Oral Presentation [arXiv]

Last Iterate Risk Bounds of SGD with Decaying Stepsize for Overparameterized Linear Regression
Jingfeng Wu*, Difan Zou*, Vladimir Braverman, Quanquan Gu and Sham M. Kakade, in Proc. of the 39th International Conference on Machine Learning (ICML), Baltimore, MD, USA, 2022. Long presentation [arXiv]

The Benefits of Implicit Regularization from SGD in Least Squares Problems
Difan Zou*, Jingfeng Wu*, Vladimir Braverman, Quanquan Gu, Dean P. Foster and Sham M. Kakade, in Proc. of Advances in Neural Information Processing Systems (NeurIPS) 34, 2021. [arXiv]

Risk Bounds for Over-parameterized Maximum Margin Classification on Sub-Gaussian Mixtures
Yuan Cao, Quanquan Gu, Mikhail Belkin, in Proc. of Advances in Neural Information Processing Systems (NeurIPS) 34, 2021. [arXiv]

Benign Overfitting of Constant-Stepsize SGD for Linear Regression
Difan Zou, Jingfeng Wu, Vladimir Braverman, Quanquan Gu and Sham M. Kakade, in Proc. of the 34th Annual Conference on Learning Theory (COLT), 2021. [arXiv]

Nearly Minimax Optimal Reinforcement Learning for Linear Mixture Markov Decision Processes
Dongruo Zhou, Quanquan Gu and Csaba Szepesvári, in Proc. of the 34th Annual Conference on Learning Theory (COLT), 2021. [arXiv]

Agnostic Learning of Halfspaces with Gradient Descent via Soft Margins
Spencer Frei, Yuan Cao and Quanquan Gu, in Proc. of the 38th International Conference on Machine Learning (ICML), 2021. Long talk [arXiv]

Provably Efficient Reinforcement Learning for Discounted MDPs with Feature Mapping
Dongruo Zhou, Jiafan He and Quanquan Gu, in Proc. of the 38th International Conference on Machine Learning (ICML), 2021. [arXiv]

How Much Over-parameterization Is Sufficient to Learn Deep ReLU Networks?
Zixiang Chen*, Yuan Cao*, Difan Zou* and Quanquan Gu, in Proc. of the 9th International Conference on Learning Representations (ICLR), 2021. [arXiv]

A Generalized Neural Tangent Kernel Analysis for Two-layer Neural Networks
Zixiang Chen, Yuan Cao, Quanquan Gu and Tong Zhang, in Proc. of Advances in Neural Information Processing Systems (NeurIPS) 33, 2020. [arXiv]

Generalization Bounds of Stochastic Gradient Descent for Wide and Deep Neural Networks
Yuan Cao and Quanquan Gu, in Proc. of Advances in Neural Information Processing Systems (NeurIPS) 32, Vancouver, Canada, 2019. Spotlight presentation [arXiv]

An Improved Analysis of Training Over-parameterized Deep Neural Networks
Difan Zou and Quanquan Gu, in Proc. of Advances in Neural Information Processing Systems (NeurIPS) 32, Vancouver, Canada, 2019. [arXiv]

Gradient Descent Optimizes Over-parameterized Deep ReLU Networks
Difan Zou*, Yuan Cao*, Dongruo Zhou and Quanquan Gu, Accepted by the Machine Learning Journal (MLJ), 2019. [arXiv]

Lower Bounds for Smooth Nonconvex Finite-Sum Optimization
Dongruo Zhou and Quanquan Gu, in Proc. of the 36th International Conference on Machine Learning (ICML), Long Beach, CA, USA, 2019. [arXiv]

Stochastic Nested Variance Reduction for Nonconvex Optimization
Dongruo Zhou, Pan Xu and Quanquan Gu, In Proc. of Advances in Neural Information Processing Systems (NeurIPS) 31, Montréal, Canada, 2018. Spotlight presentation [arXiv]

Recent Services

Senior Area Chair for NeurIPS 2023, Area Chair for ICLR 2024, AISTATS 2024, AAAI 2024

Awards

WSDM Test of Time Paper Award, 2024

Alfred P. Sloan Research Fellowship, 2022

JP Morgan Faculty Research Award, 2022

IJCAI Early Career Spotlight, 2020

AWS Machine Learning Research Award, 2019

Simons Berkeley Research Fellowship, 2019

Adobe Data Science Research Award, 2018

Salesforce Deep Learning Research Award, 2018

NSF CAREER Award, 2017

Yahoo! Academic Career Enhancement Award, 2015

Contact

Address: EVI 382, 404 Westwood Plaza, Los Angeles, CA 90095

Email: qgu at cs dot ucla dot edu

Tweets by QuanquanGu




Page generated by jemdoc.

