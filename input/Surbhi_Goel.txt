Professor: Surbhi Goel
University: University of Pennsylvania
URL: https://www.surbhigoel.com/
Description: Home
Talks
Publications
Contact
Surbhi Goel
Assistant Professor
University of Pennsylvania, Philadelphia

I am the Magerman Term Assistant Professor of Computer and Information Science at University of Pennsylvania. I am associated with the theory group, the ASSET Center on safe, explainable, and trustworthy AI systems, and the Warren Center for network and data sciences. My research interests lie at the intersection of theoretical computer science and machine learning, with a focus on developing theoretical foundations for modern machine learning paradigms, particularly deep learning. My group’s research is genererously supported by Microsoft Research and OpenAI.

Prior to this, I was a postdoctoral researcher at Microsoft Research NYC in the Machine Learning group. I obtained my Ph.D. in the Computer Science department at the University of Texas at Austin where I was fortunate to be advised by Adam Klivans. My dissertation was awarded UTCS’s Bert Kay Dissertation award, and my Ph.D. research was generously supported by the JP Morgan AI Fellowship and fellowships from UT Austin. During my PhD, I visited IAS at Princeton and the Simons Institute for the Theory of Computing at UC Berkeley (supported by the Simons-Berkeley Research Fellowship). Before that, I received my Bachelors degree from Indian Institute of Technology (IIT) Delhi.

I am actively involved in service and outreach roles. Along with Nika Haghtalab and Ellen Vitercik, I co-founded Learning Theory Alliance (LeT‐All), a community building and mentorship initiative for the learning theory community. I am currently serving as the Office Hours co-chair for ICLR 2024, and co-treasurer for the Association for Computational Learning Theory. I am also co‐organizing the Special Year on Large Language Models from Fall 2024 - Spring 2025 at the Simons Institute for the Theory of Computing.

Students: I currently advise Ezra Edelman (they/them). I am fortunate to also collaborate with several undergraduate, masters, and PhD students at UPenn who I do not directly advise.

Teaching: Currently I am co-teaching CIS 5200: Machine Learning with Eric Wong. In Fall 2023, I taught a special topics course CIS 7000: Foundations of Modern Machine Learning: Theory and Empirics. In Spring 2023, I co-taught CIS 5200: Machine Learning with Eric.

For prospective students who are interested in working with me: Please apply to the CIS PhD program and list me as a potential advisor. Unfortunately I will not be able to respond to individual emails from prospective PhD applicants at this time. If you are a current UPenn student looking to do an independent research project, send me an email with your CV, an overview of your research interests, and a brief description of 1-2 recent papers (not necessarily mine) you have read and enjoyed. I do not have any current opportunities for external students.

I recently started a blog: Unproven Algorithms. Check it out!

 Download my resumé.

Interests
Theory
Machine Learning
Education

PhD in Computer Science, 2020

University of Texas at Austin

MS in Computer Science, 2019

University of Texas at Austin

BTech in Computer Science and Engineering, 2015

Indian Institute of Technology, Delhi

Recent & Upcoming Talks
Understanding Training Dynamics in Deep Learning using Simplified Models
March 2024 UPenn
Beyond Worst-case Sequential Prediction: Adversarial Robustness via Abstention
March 2024 JHU
Beyond Worst-case Sequential Prediction: Adversarial Robustness via Abstention
March 2024 IPAM, UCLA
How do Large Language Models Think?
February 2024 UPenn
Thinking Fast with Transformers: Algorithmic Reasoning via Shortcuts
December 2023 UT Austin
SEE ALL EVENTS 
Recent Publications & Preprints
 GuanWen Qiu, Da Kuang, Surbhi Goel (2024). Complexity Matters: Dynamics of Feature Learning in the Presence of Spurious Correlations.

PDF Cite

 Benjamin L. Edelman, Ezra Edelman, Surbhi Goel, Eran Malach, Nikos Tsilivis (2024). The Evolution of Statistical Induction Heads: In-Context Learning Markov Chains.

PDF Cite

 Benjamin L. Edelman, Surbhi Goel, Sham Kakade, Eran Malach, Cyril Zhang (2023). Pareto Frontiers in Neural Feature Learning: Data, Compute, Width, and Luck. NeurIPS 2023 [Spotlight].

PDF Cite

 Surbhi Goel, Steve Hanneke, Shay Moran, Abhishek Shetty (2023). Adversarial Resilience in Sequential Prediction via Abstention. NeurIPS 2023.

PDF Cite

 Bingbin Liu, Jordan T. Ash, Surbhi Goel, Akshay Krishnamurthy, Cyril Zhang (2023). Exposing Attention Glitches with Flip-Flop Language Modeling. NeurIPS 2023 [Spotlight].

PDF Cite

 Sitan Chen, Zehao Dou, Surbhi Goel, Adam R. Klivans, Raghu Meka (2023). Learning Narrow One-Hidden-Layer ReLU Networks. COLT 2023.

PDF Cite

SEE ALL PUBLICATIONS 
Contact
surbhig@cis.upenn.edu
DM Me

Published with Wowchemy — the free, open source website builder that empowers creators.

