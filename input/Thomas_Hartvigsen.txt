Professor: Thomas Hartvigsen
University: University of Virginia
URL: https://www.tomhartvigsen.com/
Description: Skip to main content
Skip to navigation
Tom Hartvigsen	
HomeBioPublicationsGroupCVNews
	

Tom Hartvigsen

Assistant Professor

Data Science

University of Virginia

Contact: hartvigsen@virginia.edu

(Office: 1919 Ivy Rd., Rm. 339)

    
★ News ★

July'24

Papers accepted to COLM'24 on multilingual toxicity in LLMs and AIES'24 on detecting implicit social biases in VL models

New preprint on composable interventions for LLMs

June'24

Paper accepted to MICCAI'24 on federated learning for medical imaging

New preprints on evaluating LLMs for time series forecasting, and robustness of LLMs on biomedical benchmarks

May'24

Paper accepted to ACL'24 on categorical knowledge editing for LLMs

New preprint on clinical reasoning in VLMs

Organized ICLR'24 Workshop on Time Series for Health

Apr'24

Nature Medicine paper on bias in computational pathology

New preprints on time series reasoning with language models and time series foundation models

Invited talks on model editing at UMass Amherst, IBM Research, and Arizona State University

[Feb'24] Knowledge and Information Systems paper on explaining multi-class time series classifiers

[Feb'24] New preprints on label noise in time series and generating math word problems

[Jan'24] Talks at Dartmouth CS, UCSF/UC Berkeley, and the University of Alabama, Birmingham

[Dec'23] Presenting two papers at NeurIPS'23

PI on UVA Darden Business School grant to work on editing and debiasing LLMs and Co-PI on UVA Environmental Institute grant to work on climate imaging.




Hi! I'm an Assistant Professor of Data Science and, by courtesy, Computer Science at the University of Virginia. I joined UVA in Fall 2023. Before that, I was a postdoc at MIT CSAIL working with Marzyeh Ghassemi. I did my PhD in Data Science at WPI where I was advised by Elke Rundensteiner and Xiangnan Kong.

Research

I'm broadly interested in machine learning and natural language processing. I work to build methods and tools that enable responsible model deployment in ever-changing environments, especially for health.

These days, I'm especially interested in:

Model editing and continually updating large language models

Aging with GRACE: Lifelong Model Editing with Discrete Key-Value Adapters (NeurIPS'23 + code + blog post)

TAXI: Evaluating categorical knowledge editing for language models (ACL'24 + data)

Composable interventions for language models (preprint'24)

Interfacing language with time series

Are Language Models Actually Useful for Time Series Forecasting? (preprint'24)

Language Models Still Struggle to Reason about Time Series (preprint'24)

Detecting and mitigating harmful biases and toxicity in language models

PolygloToxicityPrompts: Multilingual Evaluation of Neural Toxic Degeneration in Large Language Models (COLM'24 + Leaderboard + blog post)

ToxiGen: Using LLMs to detect and mitigate implicit social biases (ACL'22 + dataset). ToxiGen has been used while training Llama2, Code Llama, phi-1.5, phi-2, and other LLMs, and to detect toxicity in Econ Forums and Laws.

Applications to healthcare and medicine

Demographic Bias in Misdiagnosis by Computational Pathology Models (Nature Medicine)

Language Models are Surprisingly Fragile to Drug Names in Biomedical Benchmarks (preprint'24 + leaderboard)



In the News

Our work drawing lessons from aviation safety for health AI was covered by MIT News and Innovate Healthcare

GRACE was featured in the Microsoft Research blog

ToxiGen was covered by TechCrunch and Microsoft Research

Our work on Fair Explainability was covered by MIT News

Misc

Outside of research, I enjoy bouldering, biking, books (science fiction/science fact), birding, juggling, vegan cooking, and playing guitar. I also spent a summer living at BioSphere 2 in Arizona.

Google Sites
Report abuse

